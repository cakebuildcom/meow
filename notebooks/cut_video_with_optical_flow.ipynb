{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00edcd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils.video import count_frames\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e246eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_FOLDER = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_L_path = os.path.join(DATA_FOLDER, \"keparoicam_clipL_synchronized.mp4\")\n",
    "video_R_path = os.path.join(DATA_FOLDER, \"keparoicam_clipR_synchronized.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_left_capture = cv2.VideoCapture(video_L_path)\n",
    "video_right_capture = cv2.VideoCapture(video_R_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_n_frames = int(video_left_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "right_n_frames = int(video_right_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(left_n_frames)\n",
    "print(right_n_frames)\n",
    "\n",
    "total_frames = min(left_n_frames, right_n_frames)\n",
    "print(total_frames)\n",
    "\n",
    "left_width = int(video_left_capture.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "left_height = int(video_left_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "left_fps = video_left_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "right_width = int(video_right_capture.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "right_height = int(video_right_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "right_fps = video_right_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(left_width)\n",
    "print(left_height)\n",
    "print(left_fps)\n",
    "\n",
    "print(right_width)\n",
    "print(right_height)\n",
    "print(right_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fps = 60.0\n",
    "final_height = 1080\n",
    "final_width = 1920\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(DATA_FOLDER, \"example_keparoiCam_of.avi\")\n",
    "video_output = cv2.VideoWriter(video_path, fourcc, final_fps, (final_width,final_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ce8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_histogram(rgb_image):\n",
    "    r_image, g_image, b_image = cv2.split(rgb_image)\n",
    "\n",
    "    r_image_eq = cv2.equalizeHist(r_image)\n",
    "    g_image_eq = cv2.equalizeHist(g_image)\n",
    "    b_image_eq = cv2.equalizeHist(b_image)\n",
    "\n",
    "    image_eq = cv2.merge([r_image_eq, g_image_eq, b_image_eq])\n",
    "    return image_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "def apply_clahe(image):\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    image_lab[...,0] = clahe.apply(image_lab[...,0])\n",
    "\n",
    "    bgr_clahe_image = cv2.cvtColor(image_lab, cv2.COLOR_LAB2BGR)\n",
    "    rgb_clahe_image = cv2.cvtColor(bgr_clahe_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return rgb_clahe_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90365d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, equalize_hist=True, clahe=False):\n",
    "    if equalize_hist:\n",
    "        image = equalize_histogram(image)\n",
    "    if clahe:\n",
    "        image = apply_clahe(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def preprocess_images(images):\n",
    "    preprocessed_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        preprocessed_images.append(preprocessed_image)\n",
    "        \n",
    "    return preprocessed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ff8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optical_flow(frame, frame2):\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray1 = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "    \n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.GaussianBlur(gray2, (21, 21), 0)\n",
    "\n",
    "    frame_delta = cv2.absdiff(gray1, gray2)\n",
    "\n",
    "    thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    ones = thresh == 255\n",
    "    ones_flat = ones.flatten()\n",
    "\n",
    "    optical_flow = np.sum(ones_flat)\n",
    "    \n",
    "    return optical_flow\n",
    "\n",
    "def calculate_optical_flow_score_from_mask(mask):\n",
    "    gray_mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray_mask, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    ones = gray_mask == 255\n",
    "    ones_flat = ones.flatten()\n",
    "    optical_flow_score = np.sum(ones_flat)\n",
    "    \n",
    "    return optical_flow_score\n",
    "\n",
    "def calculate_dense_optical_flow(frame1, frame2):\n",
    "    frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = np.zeros_like(frame1)\n",
    "    hsv[..., 1] = 255\n",
    "    \n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY) if len(frame2.shape) == 3 else frame2\n",
    "    flow = cv2.calcOpticalFlowFarneback(frame1_gray, frame2_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    optical_flow_score = calculate_optical_flow_score_from_mask(bgr_flow)\n",
    "    \n",
    "    return optical_flow_score\n",
    "    \n",
    "\n",
    "def calculate_optical_flow_with_background(frame, background_frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    frame_delta = cv2.absdiff(frame, background_frame)\n",
    "\n",
    "    thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    # thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    ones = thresh == 255\n",
    "    ones_flat = ones.flatten()\n",
    "\n",
    "    optical_flow = np.sum(ones_flat)\n",
    "    \n",
    "    return optical_flow\n",
    "\n",
    "def calculate_optical_flow_metric_with_background(frames, background_frame):\n",
    "    n_frames = len(frames)\n",
    "    n_frames_middle = int(math.floor(n_frames/2))\n",
    "    \n",
    "    total_optical_flow = 0\n",
    "    \n",
    "    for frame in frames[::5]:\n",
    "        total_optical_flow += calculate_dense_optical_flow(frame, background_frame)\n",
    "        \n",
    "    return total_optical_flow\n",
    "\n",
    "def calculate_optical_flow_metric(frames):\n",
    "    n_frames = len(frames)\n",
    "    n_frames_middle = int(math.floor(n_frames/2))\n",
    "    \n",
    "    total_optical_flow = 0\n",
    "    \n",
    "    #for frame1, frame2 in zip(frames[0:n_frames_middle], frames[n_frames_middle:n_frames]):\n",
    "    #    total_optical_flow += calculate_optical_flow(frame1, frame2)\n",
    "    \n",
    "    prev = None\n",
    "    this = None\n",
    "    for frame in frames[::5]:\n",
    "        if prev is None:\n",
    "            prev = frame\n",
    "            continue\n",
    "            \n",
    "        this = frame\n",
    "        total_optical_flow += calculate_dense_optical_flow(this, prev)\n",
    "        prev = this\n",
    "        \n",
    "    return total_optical_flow\n",
    "    \n",
    "    \n",
    "def write_frames(output_handle, frames):\n",
    "    for frame in frames:\n",
    "        output_handle.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_background(video_capture):\n",
    "    \n",
    "    random_frames = []\n",
    "    \n",
    "    frame_ids = [int(math.floor(id)) for id in video_capture.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=200)]\n",
    "    \n",
    "    for frame_id in frame_ids:\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        ret, frame = video_capture.read()\n",
    "        # frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "        random_frames.append(frame)\n",
    "\n",
    "    randon_frames_np = np.array(random_frames)\n",
    "        \n",
    "    print(randon_frames_np.shape)\n",
    "        \n",
    "    median_frame = np.median(randon_frames_np, axis=0).astype(dtype=np.uint8)   \n",
    "    \n",
    "    median_frame = cv2.cvtColor(median_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return median_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14677547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without background estimation\n",
    "\n",
    "captured_frames = []\n",
    "\n",
    "optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "for i in tqdm(range(n_windows)):\n",
    "    \n",
    "    left_frames = []\n",
    "    right_frames = []\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_left_capture.read()\n",
    "        if res:\n",
    "            left_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_right_capture.read()\n",
    "        if res:\n",
    "            right_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "\n",
    "    \n",
    "    left_optical_flow = calculate_optical_flow_metric(left_frames)\n",
    "    right_optical_flow = calculate_optical_flow_metric(right_frames)\n",
    "    \n",
    "    if left_optical_flow > right_optical_flow:\n",
    "        images_processed = preprocess_images(left_frames)\n",
    "    else:\n",
    "        images_processed = preprocess_images(right_frames)\n",
    "\n",
    "    write_frames(video_output, images_processed)\n",
    "\n",
    "video_left_capture.release()\n",
    "video_right_capture.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_camera_background = estimate_background(video_left_capture)\n",
    "right_camera_background = estimate_background(video_right_capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With background estimation\n",
    "\n",
    "captured_frames = []\n",
    "\n",
    "optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "# left_camera_background = estimate_background(video_left_capture)\n",
    "# right_camera_background = estimate_background(video_right_capture)\n",
    "\n",
    "\n",
    "for i in tqdm(range(n_windows)):\n",
    "    \n",
    "    left_frames = []\n",
    "    right_frames = []\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_left_capture.read()\n",
    "        if res:\n",
    "            left_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_right_capture.read()\n",
    "        if res:\n",
    "            right_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "\n",
    "    left_optical_flow = calculate_optical_flow_metric_with_background(left_frames, left_camera_background)\n",
    "    right_optical_flow = calculate_optical_flow_metric_with_background(right_frames, right_camera_background)\n",
    "    \n",
    "    if left_optical_flow > right_optical_flow:\n",
    "        # images_processed = preprocess_images(left_frames)\n",
    "        images_processed = left_frames\n",
    "    else:\n",
    "        # images_processed = preprocess_images(right_frames)\n",
    "        images_processed = right_frames\n",
    "        \n",
    "    write_frames(video_output, images_processed)\n",
    "\n",
    "video_left_capture.release()\n",
    "video_right_capture.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "\n",
    "def calculate_humans_from_frames(frames):\n",
    "    n_of_humans = 0\n",
    "    \n",
    "    for frame in frames[::5]:\n",
    "        # frame = cv2.resize(frame, (640, 480))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        boxes, weights = hog.detectMultiScale(gray, winStride=(8,8) )\n",
    "        \n",
    "        #boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "        #for (xA, yA, xB, yB) in boxes:\n",
    "        #    cv2.rectangle(frame, (xA, yA), (xB, yB),(0, 255, 0), 2)\n",
    "        \n",
    "        n_of_humans += len(boxes)\n",
    "        \n",
    "    return n_of_humans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af68681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With human detection\n",
    "\n",
    "captured_frames = []\n",
    "\n",
    "optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "# left_camera_background = estimate_background(video_left_capture)\n",
    "# right_camera_background = estimate_background(video_right_capture)\n",
    "\n",
    "prev = None\n",
    "\n",
    "for i in tqdm(range(n_windows)):\n",
    "    \n",
    "    left_frames = []\n",
    "    right_frames = []\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_left_capture.read()\n",
    "        if res:\n",
    "            left_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_right_capture.read()\n",
    "        if res:\n",
    "            right_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "\n",
    "    left_n_of_humans = calculate_humans_from_frames(left_frames)\n",
    "    right_n_of_humans = calculate_humans_from_frames(right_frames)\n",
    "    \n",
    "    if left_n_of_humans == right_n_of_humans:\n",
    "        if prev == 'left':\n",
    "            left_n_of_humans += 1\n",
    "        else:\n",
    "            right_n_of_humans += 1\n",
    "    \n",
    "    if left_n_of_humans > right_n_of_humans:\n",
    "        images_processed = preprocess_images(left_frames)\n",
    "        prev = \"left\"\n",
    "    else:\n",
    "        images_processed = preprocess_images(right_frames)\n",
    "        prev = \"right\"\n",
    "\n",
    "    write_frames(video_output, images_processed)\n",
    "\n",
    "video_left_capture.release()\n",
    "video_right_capture.release()\n",
    "video_output.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e8fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac664fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meow",
   "language": "python",
   "name": "meow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
