{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.dirname(os.getcwd())\n",
    "DATA_PATH = os.path.join(ROOT_PATH, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_test_image = cv2.imread(os.path.join(DATA_PATH, \"keparoi_left_frame.jpg\"))\n",
    "right_test_image = cv2.imread(os.path.join(DATA_PATH, \"keparoi_right_frame.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left_test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8686581",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(right_test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378dcc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_keparoicam_L = os.path.join(DATA_PATH, \"keparoicam_clipL_synchronized.mp4\")\n",
    "video_keparoicam_R = os.path.join(DATA_PATH, \"keparoicam_clipR_synchronized.mp4\")\n",
    "\n",
    "video_left_capture = cv2.VideoCapture(video_keparoicam_L)\n",
    "video_right_capture = cv2.VideoCapture(video_keparoicam_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_left, left_frame = video_left_capture.read()\n",
    "ret_right, right_frame = video_right_capture.read()\n",
    "\n",
    "print(ret_left)\n",
    "print(ret_right)\n",
    "\n",
    "video_left_capture.release()\n",
    "video_right_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3167e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(right_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(os.path.join(DATA_PATH, \"keparoi_left_frame_aligned.jpg\"), left_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f889da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(os.path.join(DATA_PATH, \"keparoi_right_frame_aligned.jpg\"), right_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ad8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sift(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    (kps, features) = sift.detectAndCompute(image, None)\n",
    "    kps = np.float32([kp.pt for kp in kps])\n",
    "    return (kps, features)\n",
    "\n",
    "def match_keypoints_and_homography(keypoints1, keypoints2, features1, features2, ratio, reprojection_thresh):\n",
    "    matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "    raw_matches = matcher.knnMatch(features1, features2, 2)\n",
    "    matches = []\n",
    "    \n",
    "    for match in raw_matches:\n",
    "        if len(match) == 2 and match[0].distance < match[1].distance * ratio:\n",
    "            matches.append((match[0].trainIdx, match[0].queryIdx))\n",
    "        \n",
    "    # computing a homography requires at least 4 matches\n",
    "    if len(matches) < 4:\n",
    "        return None\n",
    "    else:\n",
    "        # construct the two sets of points\n",
    "        points1 = np.float32([keypoints1[i] for (_, i) in matches])\n",
    "        points2 = np.float32([keypoints2[i] for (i, _) in matches])\n",
    "        # compute the homography between the two sets of points\n",
    "        (H, status) = cv2.findHomography(points1, points2, cv2.RANSAC, reprojection_thresh)\n",
    "        # return the matches along with the homograpy matrix\n",
    "        # and status of each matched point\n",
    "        return (matches, H, status)\n",
    "\n",
    "\n",
    "def cylindrical_warp(img, K):\n",
    "    \"\"\"This function returns the cylindrical warp for a given image and intrinsics matrix K\"\"\"\n",
    "    h_,w_ = img.shape[:2]\n",
    "    y_i, x_i = np.indices((h_,w_))\n",
    "    # Convert to homogeneous coordinates\n",
    "    X = np.stack([x_i, y_i, np.ones_like(x_i)], axis=-1).reshape(h_*w_,3) \n",
    "    Kinv = np.linalg.inv(K) \n",
    "    X = Kinv.dot(X.T).T\n",
    "    # Calculate cylindrical coords (sin\\theta, h, cos\\theta)\n",
    "    A = np.stack([np.sin(X[:,0]),X[:,1],np.cos(X[:,0])],axis=-1).reshape(w_*h_,3)\n",
    "    # Project back to image-pixels plane\n",
    "    B = K.dot(A.T).T \n",
    "    # Convert back from homogeneous coordinates\n",
    "    B = B[:,:-1] / B[:,[-1]]\n",
    "    # Make sure warp coords only within image bounds\n",
    "    B[(B[:,0] < 0) | (B[:,0] >= w_) | (B[:,1] < 0) | (B[:,1] >= h_)] = -1\n",
    "    B = B.reshape(h_,w_,-1)\n",
    "    \n",
    "    # For transparent borders\n",
    "    img_rgba = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA)\n",
    "    # Warp the image according to cylindrical coords\n",
    "    return cv2.remap(img_rgba, B[:,:,0].astype(np.float32), B[:,:,1].astype(np.float32), cv2.INTER_AREA, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    \n",
    "# K is intrinsic matrix\n",
    "def stitch_with_cylindrical_projection(image1, image2, K, ratio=0.75, reprojection_thresh=4.0):\n",
    "    \n",
    "    image2, image1 = image1, image2\n",
    "    \n",
    "    image1_undistorted = cylindrical_warp(image1, K)\n",
    "    image2_undistorted = cylindrical_warp(image2, K)\n",
    "    \n",
    "    plt.imshow(image1_undistorted)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(image2_undistorted)\n",
    "    plt.show()\n",
    "    \n",
    "    keypoints1, features1 = apply_sift(image1_undistorted)\n",
    "    keypoints2, features2 = apply_sift(image2_undistorted)\n",
    "    \n",
    "    M = match_keypoints_and_homography(keypoints1, keypoints2, features1, features2, ratio, reprojection_thresh)\n",
    "    \n",
    "    (matches, H, status) = M\n",
    "\n",
    "    if M is None:\n",
    "        return None\n",
    "    \n",
    "    result = cv2.warpPerspective(image1_undistorted, M[1],\n",
    "        (image1_undistorted.shape[1] + image2_undistorted.shape[1] + 1000, image1_undistorted.shape[0] + 1000))\n",
    "    \n",
    "    result[0:image2_undistorted.shape[0], 0:image2_undistorted.shape[1]] = image2_undistorted\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2131aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.load(os.path.join(DATA_PATH, \"camera_matrix.npy\"))\n",
    "distortion = np.load(os.path.join(DATA_PATH, \"camera_distortion.npy\"))\n",
    "h, w, d = left_frame.shape\n",
    "\n",
    "print(K)\n",
    "print(distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf790a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[2350,0,w/2],[0,2350,h/2],[0,0,1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687128cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_warped = cylindrical_warp(left_frame, K)\n",
    "plt.imshow(left_warped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523448c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, d = left_frame.shape\n",
    "\n",
    "calibration_matrix, roi = cv2.getOptimalNewCameraMatrix(K, distortion, (w,h), 0, (w,h))\n",
    "left_undistorted_image = cv2.undistort(left_frame, K, distortion, None, calibration_matrix)\n",
    "plt.imshow(left_undistorted_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, dim = right_frame.shape\n",
    "\n",
    "panorama = stitch_with_cylindrical_projection(left_frame, right_frame, K)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(panorama)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef2cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meow",
   "language": "python",
   "name": "meow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
