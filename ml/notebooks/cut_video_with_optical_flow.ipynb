{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00edcd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils.video import count_frames\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e246eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_FOLDER = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_L_path = os.path.join(DATA_FOLDER, \"keparoicam_clipL_synchronized.mp4\")\n",
    "video_R_path = os.path.join(DATA_FOLDER, \"keparoicam_clipR_synchronized.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_left_capture = cv2.VideoCapture(video_L_path)\n",
    "video_right_capture = cv2.VideoCapture(video_R_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_n_frames = int(video_left_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "right_n_frames = int(video_right_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(left_n_frames)\n",
    "print(right_n_frames)\n",
    "\n",
    "total_frames = min(left_n_frames, right_n_frames)\n",
    "print(total_frames)\n",
    "\n",
    "left_width = int(video_left_capture.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "left_height = int(video_left_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "left_fps = video_left_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "right_width = int(video_right_capture.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "right_height = int(video_right_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "right_fps = video_right_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(left_width)\n",
    "print(left_height)\n",
    "print(left_fps)\n",
    "\n",
    "print(right_width)\n",
    "print(right_height)\n",
    "print(right_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fps = 60.0\n",
    "final_height = 1080\n",
    "final_width = 1920\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(DATA_FOLDER, \"example_keparoiCam_of.avi\")\n",
    "video_output = cv2.VideoWriter(video_path, fourcc, final_fps, (final_width,final_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ce8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_histogram(rgb_image):\n",
    "    r_image, g_image, b_image = cv2.split(rgb_image)\n",
    "\n",
    "    r_image_eq = cv2.equalizeHist(r_image)\n",
    "    g_image_eq = cv2.equalizeHist(g_image)\n",
    "    b_image_eq = cv2.equalizeHist(b_image)\n",
    "\n",
    "    image_eq = cv2.merge([r_image_eq, g_image_eq, b_image_eq])\n",
    "    return image_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "def apply_clahe(image):\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    image_lab[...,0] = clahe.apply(image_lab[...,0])\n",
    "\n",
    "    bgr_clahe_image = cv2.cvtColor(image_lab, cv2.COLOR_LAB2BGR)\n",
    "    rgb_clahe_image = cv2.cvtColor(bgr_clahe_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return rgb_clahe_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90365d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, equalize_hist=True, clahe=False):\n",
    "    if equalize_hist:\n",
    "        image = equalize_histogram(image)\n",
    "    if clahe:\n",
    "        image = apply_clahe(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def preprocess_images(images):\n",
    "    preprocessed_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        preprocessed_images.append(preprocessed_image)\n",
    "        \n",
    "    return preprocessed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ff8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optical_flow(frame, frame2):\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray1 = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "    \n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.GaussianBlur(gray2, (21, 21), 0)\n",
    "\n",
    "    frame_delta = cv2.absdiff(gray1, gray2)\n",
    "\n",
    "    thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    ones = thresh == 255\n",
    "    ones_flat = ones.flatten()\n",
    "\n",
    "    optical_flow = np.sum(ones_flat)\n",
    "    \n",
    "    return optical_flow\n",
    "\n",
    "def calculate_optical_flow_score_from_mask(mask):\n",
    "    gray_mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray_mask, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    ones = gray_mask == 255\n",
    "    ones_flat = ones.flatten()\n",
    "    optical_flow_score = np.sum(ones_flat)\n",
    "    \n",
    "    return optical_flow_score\n",
    "\n",
    "def calculate_dense_optical_flow(frame1, frame2):\n",
    "    frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = np.zeros_like(frame1)\n",
    "    hsv[..., 1] = 255\n",
    "    \n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY) if len(frame2.shape) == 3 else frame2\n",
    "    flow = cv2.calcOpticalFlowFarneback(frame1_gray, frame2_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    optical_flow_score = calculate_optical_flow_score_from_mask(bgr_flow)\n",
    "    \n",
    "    return optical_flow_score\n",
    "    \n",
    "\n",
    "def calculate_optical_flow_with_background(frame, background_frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    frame_delta = cv2.absdiff(frame, background_frame)\n",
    "\n",
    "    thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    # thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    ones = thresh == 255\n",
    "    ones_flat = ones.flatten()\n",
    "\n",
    "    optical_flow = np.sum(ones_flat)\n",
    "    \n",
    "    return optical_flow\n",
    "\n",
    "def calculate_optical_flow_metric_with_background(frames, background_frame):\n",
    "    n_frames = len(frames)\n",
    "    n_frames_middle = int(math.floor(n_frames/2))\n",
    "    \n",
    "    total_optical_flow = 0\n",
    "    \n",
    "    for frame in frames[::5]:\n",
    "        total_optical_flow += calculate_dense_optical_flow(frame, background_frame)\n",
    "        \n",
    "    return total_optical_flow\n",
    "\n",
    "def calculate_optical_flow_metric(frames):\n",
    "    n_frames = len(frames)\n",
    "    n_frames_middle = int(math.floor(n_frames/2))\n",
    "    \n",
    "    total_optical_flow = 0\n",
    "    \n",
    "    #for frame1, frame2 in zip(frames[0:n_frames_middle], frames[n_frames_middle:n_frames]):\n",
    "    #    total_optical_flow += calculate_optical_flow(frame1, frame2)\n",
    "    \n",
    "    prev = None\n",
    "    this = None\n",
    "    for frame in frames[::5]:\n",
    "        if prev is None:\n",
    "            prev = frame\n",
    "            continue\n",
    "            \n",
    "        this = frame\n",
    "        total_optical_flow += calculate_dense_optical_flow(this, prev)\n",
    "        prev = this\n",
    "        \n",
    "    return total_optical_flow\n",
    "    \n",
    "    \n",
    "def write_frames(output_handle, frames):\n",
    "    for frame in frames:\n",
    "        output_handle.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_background(video_capture, n_frames=100, min_frame=0, max_frame=np.inf):\n",
    "    \n",
    "    random_frames = []\n",
    "    \n",
    "    if np.isinf(max_frame):\n",
    "        max_frame = video_capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    frame_ids = [id for id in random.sample(range(min_frame, max_frame), n_frames)]\n",
    "    \n",
    "    for frame_id in frame_ids:\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        ret, frame = video_capture.read()\n",
    "        random_frames.append(frame)\n",
    "\n",
    "    random_frames_np = np.stack(random_frames)\n",
    "    print(random_frames_np.shape)\n",
    "    first_item = random_frames_np[0]\n",
    "    print(first_item)\n",
    "    print(first_item.shape)\n",
    "    plt.imshow(first_item)\n",
    "    plt.show()\n",
    "    blues, greens, reds = random_frames_np[:,:,:,0], random_frames_np[:,:,:,1], random_frames_np[:,:,:,2]\n",
    "    \n",
    "    blues_median, greens_median, reds_median = np.mean(blues, axis=0), np.mean(greens, axis=0),  np.mean(reds, axis=0)\n",
    "    \n",
    "    print(blues_median)\n",
    "    print(greens_median)\n",
    "    print(reds_median)\n",
    "    \n",
    "    estimation = np.stack([reds_median, greens_median, blues_median], axis=2)\n",
    "    \n",
    "    print(estimation.shape)\n",
    "    \n",
    "    print(estimation)\n",
    "    return estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1310e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grayscale(frame: np.ndarray) -> bool:\n",
    "    if len(frame.shape) < 3 or frame.shape[2]  == 1:\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "def farneback_optical_flow(frame1: np.ndarray, frame2: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    if not is_grayscale(frame1):\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if not is_grayscale(frame2):\n",
    "        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        frame1, frame2, None, \n",
    "        pyr_scale = 0.5, \n",
    "        levels = 5, \n",
    "        winsize = 15, \n",
    "        iterations = 5, \n",
    "        poly_n = 5, \n",
    "        poly_sigma = 1.2, \n",
    "        flags = 0\n",
    "    )\n",
    "        \n",
    "    return flow\n",
    "    \n",
    "def visualize_farneback_optical_flow(flow, mask):\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    magnitude = np.nan_to_num(magnitude)\n",
    "    angle = np.nan_to_num(angle)\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    return rgb\n",
    "\n",
    "def calculate_flow_metric(flow):\n",
    "    gray_mask = cv2.cvtColor(flow, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_mask = cv2.GaussianBlur(gray_mask, (3, 3), 0)\n",
    "    mask_sum = np.sum(blurred_mask)\n",
    "    \n",
    "    return mask_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e67b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_estimate = estimate_background(video_left_capture, n_frames=1, min_frame=0, max_frame=30*10)\n",
    "print(np.min(bg_estimate))\n",
    "print(np.max(bg_estimate))\n",
    "plt.imshow(bg_estimate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0684b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, -1)\n",
    "video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, -1)\n",
    "\n",
    "_, first_left = video_left_capture.read()\n",
    "_, first_right = video_right_capture.read()\n",
    "\n",
    "prev_left = cv2.cvtColor(first_left, cv2.COLOR_BGR2GRAY)\n",
    "prev_right = cv2.cvtColor(first_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "mask = np.zeros_like(first_left)\n",
    "mask[..., 1] = 255\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, 1+(i*30))\n",
    "    video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, 1+(i*2))\n",
    "    \n",
    "    res_left, frame_left = video_left_capture.read()\n",
    "    res_right, frame_right = video_right_capture.read()\n",
    "\n",
    "    gray_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)\n",
    "    gray_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow_left = farneback_optical_flow(prev_left, gray_left)\n",
    "    flow_right = farneback_optical_flow(prev_right, gray_right)\n",
    "    \n",
    "    left_mask = visualize_farneback_optical_flow(flow_left, mask)\n",
    "    right_mask = visualize_farneback_optical_flow(flow_right, mask)\n",
    "    \n",
    "    left_score = calculate_flow_metric(left_mask)\n",
    "    right_score = calculate_flow_metric(right_mask)\n",
    "    \n",
    "    print(f\"Left score: {left_score}\")\n",
    "    print(f\"Right score: {right_score}\")\n",
    "    \n",
    "    if left_score == 0 or right_score == 0:\n",
    "        continue\n",
    "    \n",
    "    if left_score > right_score:\n",
    "        print(\"Choose LEFT\")\n",
    "    else:\n",
    "        print(\"Choose RIGHT\")\n",
    "    \n",
    "    prev_left = gray_left\n",
    "    prev_right = gray_right\n",
    "    \n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14677547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without background estimation\n",
    "\n",
    "captured_frames = []\n",
    "\n",
    "#optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "#n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "for i in tqdm(range(n_windows)):\n",
    "    \n",
    "    left_frames = []\n",
    "    right_frames = []\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_left_capture.read()\n",
    "        if res:\n",
    "            left_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_right_capture.read()\n",
    "        if res:\n",
    "            right_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "\n",
    "    \n",
    "    left_optical_flow = calculate_optical_flow_metric(left_frames)\n",
    "    right_optical_flow = calculate_optical_flow_metric(right_frames)\n",
    "    \n",
    "    if left_optical_flow > right_optical_flow:\n",
    "        images_processed = preprocess_images(left_frames)\n",
    "    else:\n",
    "        images_processed = preprocess_images(right_frames)\n",
    "\n",
    "    write_frames(video_output, images_processed)\n",
    "\n",
    "video_left_capture.release()\n",
    "video_right_capture.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_camera_background = estimate_background(video_left_capture)\n",
    "right_camera_background = estimate_background(video_right_capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With background estimation\n",
    "\n",
    "captured_frames = []\n",
    "\n",
    "optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "# left_camera_background = estimate_background(video_left_capture)\n",
    "# right_camera_background = estimate_background(video_right_capture)\n",
    "\n",
    "\n",
    "for i in tqdm(range(n_windows)):\n",
    "    \n",
    "    left_frames = []\n",
    "    right_frames = []\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_left_capture.read()\n",
    "        if res:\n",
    "            left_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_right_capture.read()\n",
    "        if res:\n",
    "            right_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "\n",
    "    left_optical_flow = calculate_optical_flow_metric_with_background(left_frames, left_camera_background)\n",
    "    right_optical_flow = calculate_optical_flow_metric_with_background(right_frames, right_camera_background)\n",
    "    \n",
    "    if left_optical_flow > right_optical_flow:\n",
    "        # images_processed = preprocess_images(left_frames)\n",
    "        images_processed = left_frames\n",
    "    else:\n",
    "        # images_processed = preprocess_images(right_frames)\n",
    "        images_processed = right_frames\n",
    "        \n",
    "    write_frames(video_output, images_processed)\n",
    "\n",
    "video_left_capture.release()\n",
    "video_right_capture.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "\n",
    "def calculate_humans_from_frames(frames):\n",
    "    n_of_humans = 0\n",
    "    \n",
    "    for frame in frames[::5]:\n",
    "        # frame = cv2.resize(frame, (640, 480))\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        boxes, weights = hog.detectMultiScale(gray, winStride=(8,8) )\n",
    "        \n",
    "        #boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "        #for (xA, yA, xB, yB) in boxes:\n",
    "        #    cv2.rectangle(frame, (xA, yA), (xB, yB),(0, 255, 0), 2)\n",
    "        \n",
    "        n_of_humans += len(boxes)\n",
    "        \n",
    "    return n_of_humans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af68681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With human detection\n",
    "\n",
    "captured_frames = []\n",
    "\n",
    "optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "# left_camera_background = estimate_background(video_left_capture)\n",
    "# right_camera_background = estimate_background(video_right_capture)\n",
    "\n",
    "prev = None\n",
    "\n",
    "for i in tqdm(range(n_windows)):\n",
    "    \n",
    "    left_frames = []\n",
    "    right_frames = []\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_left_capture.read()\n",
    "        if res:\n",
    "            left_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "    \n",
    "    for j in range(optical_flow_window_length):\n",
    "        frame_number = i*optical_flow_window_length + j\n",
    "        video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        res, frame = video_right_capture.read()\n",
    "        if res:\n",
    "            right_frames.append(frame)\n",
    "        else:\n",
    "            print(\"Error reading frame\")\n",
    "\n",
    "    left_n_of_humans = calculate_humans_from_frames(left_frames)\n",
    "    right_n_of_humans = calculate_humans_from_frames(right_frames)\n",
    "    \n",
    "    if left_n_of_humans == right_n_of_humans:\n",
    "        if prev == 'left':\n",
    "            left_n_of_humans += 1\n",
    "        else:\n",
    "            right_n_of_humans += 1\n",
    "    \n",
    "    if left_n_of_humans > right_n_of_humans:\n",
    "        images_processed = preprocess_images(left_frames)\n",
    "        prev = \"left\"\n",
    "    else:\n",
    "        images_processed = preprocess_images(right_frames)\n",
    "        prev = \"right\"\n",
    "\n",
    "    write_frames(video_output, images_processed)\n",
    "\n",
    "video_left_capture.release()\n",
    "video_right_capture.release()\n",
    "video_output.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e8fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac664fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
