{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ee170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import sys  \n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), \"network\"))\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), \"network\", \"data\"))\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import network.fpn as fpn\n",
    "import network.nms as nms\n",
    "from network import footandball as footandball\n",
    "from data import augmentation as augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_FOLDER = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74512f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BALL_LABEL = 1\n",
    "PLAYER_LABEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9601714",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c83389",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_FILE = os.path.join(DATA_FOLDER, \"model_20201019_1416_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_waltter_path = os.path.join(DATA_FOLDER, \"example_waltter_synchronized.mov\")\n",
    "video_vikture_path = os.path.join(DATA_FOLDER, \"example_vikture_late_15s_synchronized.mov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_left_capture = cv2.VideoCapture(video_vikture_path)\n",
    "video_right_capture = cv2.VideoCapture(video_waltter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_n_frames = int(video_left_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "right_n_frames = int(video_right_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(left_n_frames)\n",
    "print(right_n_frames)\n",
    "\n",
    "total_frames = min(left_n_frames, right_n_frames)\n",
    "\n",
    "print(total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fps = 60.0\n",
    "final_height = 1080\n",
    "final_width = 1920\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3185f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(DATA_FOLDER, \"example_human_detection_video_6.avi\")\n",
    "video_output = cv2.VideoWriter(video_path, fourcc, final_fps, (final_width , final_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee881975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    phase='detect'\n",
    "    max_player_detections=100\n",
    "    max_ball_detections=100\n",
    "    player_threshold=0.7\n",
    "    ball_threshold=0.7\n",
    "    \n",
    "    layers, out_channels = fpn.make_modules(fpn.cfg['X'], batch_norm=True)\n",
    "    lateral_channels = 32\n",
    "    i_channels = 32\n",
    "\n",
    "    base_net = fpn.FPN(layers, out_channels=out_channels, lateral_channels=lateral_channels, return_layers=[1, 3])\n",
    "    ball_classifier = nn.Sequential(nn.Conv2d(lateral_channels, out_channels=i_channels, kernel_size=3, padding=1),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(i_channels, out_channels=2, kernel_size=3, padding=1))\n",
    "    player_classifier = nn.Sequential(nn.Conv2d(lateral_channels, out_channels=i_channels, kernel_size=3, padding=1),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Conv2d(i_channels, out_channels=2, kernel_size=3, padding=1))\n",
    "    player_regressor = nn.Sequential(nn.Conv2d(lateral_channels, out_channels=i_channels, kernel_size=3, padding=1),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Conv2d(i_channels, out_channels=4, kernel_size=3, padding=1))\n",
    "    detector = footandball.FootAndBall(phase, base_net, player_regressor=player_regressor, player_classifier=player_classifier,\n",
    "                           ball_classifier=ball_classifier, ball_threshold=ball_threshold,\n",
    "                           player_threshold=player_threshold, max_ball_detections=max_ball_detections,\n",
    "                           max_player_detections=max_player_detections)\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c425954",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model = model.to(device)\n",
    "state_dict = torch.load(WEIGHT_FILE)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a96919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(image, detections):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for box, label, score in zip(detections['boxes'], detections['labels'], detections['scores']):\n",
    "        if label == PLAYER_LABEL:\n",
    "            x1, y1, x2, y2 = box\n",
    "            color = (255, 0, 0)\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "            cv2.putText(image, '{:0.2f}'.format(score), (int(x1), max(0, int(y1)-10)), font, 1, color, 2)\n",
    "\n",
    "        elif label == BALL_LABEL:\n",
    "            x1, y1, x2, y2 = box\n",
    "            x = int((x1 + x2) / 2)\n",
    "            y = int((y1 + y2) / 2)\n",
    "            color = (0, 0, 255)\n",
    "            radius = 25\n",
    "            cv2.circle(image, (int(x), int(y)), radius, color, 2)\n",
    "            cv2.putText(image, '{:0.2f}'.format(score), (max(0, int(x - radius)), max(0, (y - radius - 10))), font, 1,\n",
    "                        color, 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_histogram(rgb_image):\n",
    "    r_image, g_image, b_image = cv2.split(rgb_image)\n",
    "\n",
    "    r_image_eq = cv2.equalizeHist(r_image)\n",
    "    g_image_eq = cv2.equalizeHist(g_image)\n",
    "    b_image_eq = cv2.equalizeHist(b_image)\n",
    "\n",
    "    image_eq = cv2.merge([r_image_eq, g_image_eq, b_image_eq])\n",
    "    return image_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = equalize_histogram(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def preprocess_images(images):\n",
    "    preprocessed_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        preprocessed_images.append(preprocessed_image)\n",
    "        \n",
    "    return preprocessed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detection(images):\n",
    "\n",
    "    detection_list = []\n",
    "    annotated_frames = []\n",
    "    \n",
    "    for frame in images:\n",
    "        img_tensor = augmentations.numpy2tensor(frame)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Add dimension for the batch size\n",
    "            img_tensor = img_tensor.unsqueeze(dim=0).to(device)\n",
    "            detections = model(img_tensor)[0]\n",
    "\n",
    "            n_humans = len(detections['labels'])\n",
    "\n",
    "            detection_list.append((n_humans, detections))\n",
    "\n",
    "            frame = draw_bboxes(frame, detections)\n",
    "            annotated_frames.append(frame)\n",
    "    \n",
    "    return detection_list, annotated_frames\n",
    "\n",
    "def run_detection_single(frame):\n",
    "\n",
    "    img_tensor = augmentations.numpy2tensor(frame)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add dimension for the batch size\n",
    "        img_tensor = img_tensor.unsqueeze(dim=0).to(device)\n",
    "        detections = model(img_tensor)[0]        \n",
    "        n_humans = len(detections['labels'])\n",
    "        \n",
    "    return n_humans, detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_frames(output_handle, frames):\n",
    "    for frame in frames:\n",
    "        output_handle.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_detection_video():\n",
    "    \n",
    "    captured_frames = []\n",
    "\n",
    "    optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "    n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "    for i in tqdm(range(n_windows)):\n",
    "\n",
    "        \n",
    "        left_frames = []\n",
    "        right_frames = []\n",
    "\n",
    "        for j in range(optical_flow_window_length):\n",
    "            frame_number = i*optical_flow_window_length + j\n",
    "            video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            res, frame = video_left_capture.read()\n",
    "            if res:\n",
    "                left_frames.append(frame)\n",
    "            else:\n",
    "                print(\"Error reading frame\")\n",
    "\n",
    "        for j in range(optical_flow_window_length):\n",
    "            frame_number = i*optical_flow_window_length + j\n",
    "            video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            res, frame = video_right_capture.read()\n",
    "            if res:\n",
    "                right_frames.append(frame)\n",
    "            else:\n",
    "                print(\"Error reading frame\")\n",
    "        \n",
    "        \n",
    "        left_n_humans, left_detections = run_detection_single(left_frames[0])\n",
    "        right_n_humans, right_detections = run_detection_single(right_frames[0])\n",
    "\n",
    "        print(f\"{(optical_flow_window_length/final_fps) * i} s: left humans: {left_n_humans}, right humans: {right_n_humans}\")\n",
    "        \n",
    "        if left_n_humans > right_n_humans:\n",
    "            images_processed = preprocess_images(left_frames)\n",
    "        else:\n",
    "            images_processed = preprocess_images(right_frames)\n",
    "\n",
    "        write_frames(video_output, images_processed)\n",
    "        \n",
    "        \n",
    "    video_left_capture.release()\n",
    "    video_right_capture.release()\n",
    "    video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba7c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_detection_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_detection_video_with_annotations():\n",
    "    \n",
    "    captured_frames = []\n",
    "\n",
    "    optical_flow_window_length = int(math.floor(final_fps / 2))\n",
    "    n_windows = math.floor(total_frames/optical_flow_window_length)\n",
    "\n",
    "    for i in tqdm(range(n_windows)):\n",
    "\n",
    "        \n",
    "        left_frames = []\n",
    "        right_frames = []\n",
    "\n",
    "        for j in range(optical_flow_window_length):\n",
    "            frame_number = i*optical_flow_window_length + j\n",
    "            video_left_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            res, frame = video_left_capture.read()\n",
    "            if res:\n",
    "                left_frames.append(frame)\n",
    "            else:\n",
    "                print(\"Error reading frame\")\n",
    "\n",
    "        for j in range(optical_flow_window_length):\n",
    "            frame_number = i*optical_flow_window_length + j\n",
    "            video_right_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            res, frame = video_right_capture.read()\n",
    "            if res:\n",
    "                right_frames.append(frame)\n",
    "            else:\n",
    "                print(\"Error reading frame\")\n",
    "        \n",
    "        \n",
    "        left_detections, left_annotated_frames = run_detection(left_frames)\n",
    "        right_detections, right_annotated_frames = run_detection(right_frames)\n",
    "\n",
    "        left_humans_count = sum([i[0] for i in left_detections])\n",
    "        right_humans_count = sum([i[0] for i in right_detections])\n",
    "        \n",
    "        print(f\"{(optical_flow_window_length/final_fps) * i} s: left humans: {left_humans_count}, right humans: {right_humans_count}\")\n",
    "        \n",
    "        if left_humans_count > right_humans_count:\n",
    "            images_processed = preprocess_images(left_annotated_frames)\n",
    "        else:\n",
    "            images_processed = preprocess_images(right_annotated_frames)\n",
    "\n",
    "        write_frames(video_output, images_processed)\n",
    "        \n",
    "        \n",
    "    video_left_capture.release()\n",
    "    video_right_capture.release()\n",
    "    video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cf9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_detection_video_with_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc282e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
