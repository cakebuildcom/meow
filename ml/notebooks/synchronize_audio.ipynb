{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680bc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ffmpeg\n",
    "import moviepy.editor as mp\n",
    "from scipy.io.wavfile import read\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_FOLDER = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c101900",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_keparoicamL_path = os.path.join(DATA_FOLDER, \"keparoicam_clipL.mp4\")\n",
    "video_keparoicamR_path = os.path.join(DATA_FOLDER, \"keparoicam_clipR.mp4\")\n",
    "audio_keparoicamL_path = os.path.join(DATA_FOLDER, \"keparoicam_clipL.wav\")\n",
    "audio_keparoicamR_path = os.path.join(DATA_FOLDER, \"keparoicam_clipR.wav\")\n",
    "\n",
    "video_keparoicamL_sync_path = os.path.join(DATA_FOLDER, \"keparoicam_clipL_synchronized.mp4\")\n",
    "video_keparoicamR_sync_path = os.path.join(DATA_FOLDER, \"keparoicam_clipR_synchronized.mp4\")\n",
    "audio_keparoicamL_sync_path = os.path.join(DATA_FOLDER, \"keparoicam_clipL_synchronized.wav\")\n",
    "audio_keparoicamR_sync_path = os.path.join(DATA_FOLDER, \"keparoicam_clipR_synchronized.wav\")\n",
    "\n",
    "video_keparoicamL_A_path = os.path.join(DATA_FOLDER, \"keparoicam_left_test_A.mp4\")\n",
    "video_keparoicamR_A_path = os.path.join(DATA_FOLDER, \"keparoicam_right_test_A.mp4\")\n",
    "audio_keparoicamL_A_path = os.path.join(DATA_FOLDER, \"keparoicam_left_test_A.wav\")\n",
    "audio_keparoicamR_A_path = os.path.join(DATA_FOLDER, \"keparoicam_right_test_A.wav\")\n",
    "\n",
    "video_keparoicamL_B_path = os.path.join(DATA_FOLDER, \"keparoicam_left_test_B.mp4\")\n",
    "video_keparoicamR_B_path = os.path.join(DATA_FOLDER, \"keparoicam_right_test_B.mp4\")\n",
    "audio_keparoicamL_B_path = os.path.join(DATA_FOLDER, \"keparoicam_left_test_B.wav\")\n",
    "audio_keparoicamR_B_path = os.path.join(DATA_FOLDER, \"keparoicam_right_test_B.wav\")\n",
    "\n",
    "video_keparoicamL_C_path = os.path.join(DATA_FOLDER, \"keparoicam_left_test_C.mp4\")\n",
    "video_keparoicamR_C_path = os.path.join(DATA_FOLDER, \"keparoicam_right_test_C.mp4\")\n",
    "audio_keparoicamL_C_path = os.path.join(DATA_FOLDER, \"keparoicam_left_test_C.wav\")\n",
    "audio_keparoicamR_C_path = os.path.join(DATA_FOLDER, \"keparoicam_right_test_C.wav\")\n",
    "\n",
    "example_vikture_early_15s = os.path.join(DATA_FOLDER, \"example_vikture_early_15s.MOV\")\n",
    "example_vikture_early_30s = os.path.join(DATA_FOLDER, \"example_vikture_early_30s.MOV\")\n",
    "example_vikture_late_15s = os.path.join(DATA_FOLDER, \"example_vikture_late_15s.MOV\")\n",
    "example_vikture_late_30s = os.path.join(DATA_FOLDER, \"example_vikture_late_30s.MOV\")\n",
    "\n",
    "example_waltter_early_15s = os.path.join(DATA_FOLDER, \"example_waltter_early_15s.MOV\")\n",
    "example_waltter_early_30s = os.path.join(DATA_FOLDER, \"example_waltter_early_30s.MOV\")\n",
    "example_waltter_late_15s = os.path.join(DATA_FOLDER, \"example_waltter_late_15s.MOV\")\n",
    "example_waltter_late_30s = os.path.join(DATA_FOLDER, \"example_waltter_late_30s.MOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43bd6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_path):\n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    audio = video.audio\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(audio: mp.AudioClip, path, filename, extension=\"wav\"):\n",
    "    audio.write_audiofile(os.path.join(path, f\"{filename}.{extension}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = extract_audio(video_keparoicamR_sync_path)\n",
    "write_to_file(audio, DATA_FOLDER, \"keparoicam_clipR_synchronized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_left = audio_keparoicamL_sync_path\n",
    "target_right = audio_keparoicamR_sync_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio(data):\n",
    "    plt.title(\"Audio\")\n",
    "    plt.plot(data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_to_mono(wav_array: np.ndarray):\n",
    "    mono_wav = wav_array.mean(axis=1)\n",
    "    return mono_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dea13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_wav(wav_array: np.ndarray):\n",
    "    normalized_wav_array = 2.*(wav_array - np.min(wav_array))/np.ptp(wav_array)-1\n",
    "    return normalized_wav_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_audio(audio_array: np.ndarray):\n",
    "    return audio_array**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c83cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivate(wav_array: np.ndarray):\n",
    "    array_shifted = np.concatenate([np.array([0]), wav_array[:-1]])\n",
    "    derivate_array = wav_array - array_shifted\n",
    "    return derivate_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18fd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio_file_path: str, to_mono=True, normalize=True, contrast=True, derivate=False):\n",
    "    sample_rate, audio = read(audio_file_path)\n",
    "    audio_data = np.array(audio, dtype=float)\n",
    "    if to_mono:\n",
    "        audio_data = stereo_to_mono(audio_data)\n",
    "    if contrast:\n",
    "        audio_data = contrast_audio(audio_data)\n",
    "    if derivate:\n",
    "        audio_data = calculate_derivate(audio_data)\n",
    "    if normalize:\n",
    "        audio_data = normalize_wav(audio_data)\n",
    "\n",
    "    return audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_left = preprocess_audio(target_left, to_mono=False, normalize=False, contrast=False, derivate=False)\n",
    "audio_right = preprocess_audio(target_right, to_mono=False, normalize=False, contrast=False, derivate=False)\n",
    "\n",
    "audio_left_mono = preprocess_audio(target_left, to_mono=True, normalize=True, contrast=False, derivate=False)\n",
    "audio_right_mono = preprocess_audio(target_right, to_mono=True, normalize=True, contrast=False, derivate=False)\n",
    "\n",
    "audio_left_nd = preprocess_audio(target_left, to_mono=True, normalize=True, contrast=False, derivate=True)\n",
    "audio_right_nd = preprocess_audio(target_right, to_mono=True, normalize=True, contrast=False, derivate=True)\n",
    "\n",
    "audio_left_d = preprocess_audio(target_left, to_mono=True, normalize=False, contrast=False, derivate=True)\n",
    "audio_right_d = preprocess_audio(target_right, to_mono=True, normalize=False, contrast=False, derivate=True)\n",
    "\n",
    "\n",
    "plot_audio(audio_left)\n",
    "plot_audio(audio_right)\n",
    "\n",
    "plot_audio(audio_left_mono)\n",
    "plot_audio(audio_right_mono)\n",
    "\n",
    "plot_audio(audio_left_nd)\n",
    "plot_audio(audio_right_nd)\n",
    "\n",
    "plot_audio(audio_left_d)\n",
    "plot_audio(audio_right_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5970087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_blocks(wav_array: np.ndarray, block_size=10, overlap=0, aggregation_func=np.mean):\n",
    "    blocks = np.array([])\n",
    "    array_length = len(wav_array)\n",
    "    block_amount = math.ceil(array_length / (block_size - overlap))\n",
    "    for i in range(block_amount):\n",
    "        block_start = (block_size - overlap) * i\n",
    "        block_end = min(block_start + block_size, array_length)\n",
    "        current_block = wav_array[block_start : block_end]\n",
    "        block_aggregate = aggregation_func(current_block)\n",
    "        blocks = np.append(blocks, block_aggregate)\n",
    "        \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE between audio samples\n",
    "def audio_mse_score(audio1, audio2, blocks=False):\n",
    "    assert len(audio1) == len(audio2)\n",
    "    \n",
    "    if blocks:\n",
    "        audio1_blocks = np.array(wav_to_blocks(audio1, block_size=441, overlap=0))\n",
    "        audio2_blocks = np.array(wav_to_blocks(audio2, block_size=441, overlap=0))\n",
    "        mse_score = (np.square(audio1_blocks - audio2_blocks)).mean()\n",
    "    else:\n",
    "        mse_score = (np.square(audio1 - audio2)).mean()\n",
    "        \n",
    "    return mse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute distance between audio samples\n",
    "def audio_absolute_distance_score(audio1, audio2, blocks=False):\n",
    "    assert len(audio1) == len(audio2)\n",
    "    \n",
    "    if blocks:\n",
    "        audio1_blocks = np.array(wav_to_blocks(audio1, block_size=441, overlap=0))\n",
    "        audio2_blocks = np.array(wav_to_blocks(audio2, block_size=441, overlap=0))\n",
    "        distance_score = (np.abs(audio1_blocks - audio2_blocks)).sum()\n",
    "    else:\n",
    "        distance_score = (np.abs(audio1 - audio2)).sum()\n",
    "    \n",
    "    return distance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_rmse_score(audio1, audio2, blocks=False):\n",
    "    assert len(audio1) == len(audio2)\n",
    "    \n",
    "    mse_score = audio_mse_score(audio1, audio2, blocks=blocks)\n",
    "    rmse_score = np.sqrt(mse_score)\n",
    "        \n",
    "    return rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_division(first, second):\n",
    "    if first == 0 or second == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return first / second\n",
    "\n",
    "# Compare windows from audio1 to audio2 and find windows that minimizes the distance between audio files\n",
    "def calculate_distance_plot(audio1, audio2, verbose=False, scoring_func=audio_mse_score):\n",
    "    a1a2_distance_scores = []\n",
    "    a2a1_distance_scores = [] \n",
    "\n",
    "    # Accuracy of 100th of a second\n",
    "    window_increment = math.floor(44100 / 50)\n",
    "    window_size_factor = 2\n",
    "    \n",
    "    audio1_lenght = len(audio1)\n",
    "    window_size_1 = math.floor(audio1_lenght / window_size_factor)\n",
    "    print(f\"Windows size 1: {window_size_1}\")\n",
    "    windows_amount_1 = math.ceil((audio1_lenght - window_size_1) / window_increment)\n",
    "    \n",
    "    # We don't know which audio files is delayed compared to the other, so we need to run the analysis both ways, \n",
    "    # first comparing audio1 window to audio2 start and then comparing audio2 windows to audio1 start \n",
    "    \n",
    "    print(\"Comparing audio1 to audio2\")\n",
    "    for i in tqdm(range(windows_amount_1)):\n",
    "        window_start = window_increment * i\n",
    "        window_end = min(window_start + window_size_1, audio1_lenght)\n",
    "        audio1_window = audio1[window_start : window_end]\n",
    "        audio2_window = audio2[0 : window_size_1]\n",
    "        score = scoring_func(audio1_window, audio2_window, blocks=False)\n",
    "        a1a2_distance_scores.append(score)\n",
    "        \n",
    "        \n",
    "    audio2_lenght = len(audio2)\n",
    "    window_size_2 = math.floor(audio2_lenght / window_size_factor)\n",
    "    print(f\"Windows size 2: {window_size_2}\")\n",
    "    windows_amount_2 = math.ceil((audio2_lenght - window_size_2) / window_increment)\n",
    "\n",
    "    print(\"Comparing audio2 to audio1\")\n",
    "    for i in tqdm(range(windows_amount_2)):\n",
    "        window_start = window_increment * i\n",
    "        window_end = min(window_start + window_size_2, audio2_lenght)\n",
    "        audio1_window = audio1[0 : window_size_2]\n",
    "        audio2_window = audio2[window_start : window_end]\n",
    "        score = scoring_func(audio1_window, audio2_window, blocks=False)\n",
    "        a2a1_distance_scores.append(score)\n",
    "    \n",
    "    x_values = (np.arange(len(a1a2_distance_scores)) * window_increment) / 44100\n",
    "    plt.plot(x_values, a1a2_distance_scores)\n",
    "    plt.title(\"Audio 1 sliding window MSE\")\n",
    "    plt.xlabel(\"s\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.show()\n",
    "    \n",
    "    x_values = (np.arange(len(a2a1_distance_scores)) * window_increment) / 44100\n",
    "    plt.plot(x_values, a2a1_distance_scores)\n",
    "    plt.title(\"Audio 2 sliding window MSE\")\n",
    "    plt.xlabel(\"s\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.show()\n",
    "\n",
    "    a1a2_distance_scores_np = np.array(a1a2_distance_scores)\n",
    "    a2a1_distance_scores_np = np.array(a2a1_distance_scores)\n",
    "\n",
    "    a1a2_lowest_score_arg = np.argmin(a1a2_distance_scores_np)\n",
    "    a2a1_lowest_score_arg = np.argmin(a2a1_distance_scores_np)\n",
    "    \n",
    "    print(a1a2_lowest_score_arg)\n",
    "    print(a2a1_lowest_score_arg)\n",
    "    \n",
    "    a1a2_lowest_score = np.min(a1a2_distance_scores)\n",
    "    a2a1_lowest_score = np.min(a2a1_distance_scores)\n",
    "    \n",
    "    lowest_score = min(a1a2_lowest_score, a2a1_lowest_score)\n",
    "    lowest_score_arg = min(a1a2_lowest_score, a2a1_lowest_score)\n",
    "\n",
    "    if a1a2_lowest_score < a2a1_lowest_score:\n",
    "        delay = (a1a2_lowest_score_arg * window_increment) / 44100\n",
    "        print(f\"Audio 1 needs {delay} second delay\")\n",
    "    else:\n",
    "        delay = (a2a1_lowest_score_arg * window_increment) / 44100\n",
    "        print(f\"Audio 2 needs {delay} second delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df28ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distance_plot(audio_left_d, audio_right_d, verbose=True, scoring_func=audio_absolute_distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d80a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
